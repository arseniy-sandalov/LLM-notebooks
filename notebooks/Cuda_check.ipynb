{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4dd36d-2128-405e-9a43-2bbcb1356da7",
   "metadata": {},
   "source": [
    "#### Change the promting according to the promting of pip-sql-1.3b\n",
    "https://huggingface.co/PipableAI/pip-sql-1.3b\n",
    "\n",
    "#### Go from using langchain sql chain to manual promt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b66e310-16fa-4ef9-a9d9-4b122eee69ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from langchain.sql_database import SQLDatabase\n",
    "\n",
    "db_path = '/home/arseniy/Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹/Projects/Python/LLM_project/json-to-sql/mys_db'\n",
    "\n",
    "engine = create_engine ('sqlite:///' + db_path, echo= False, future=True)\n",
    "\n",
    "db = SQLDatabase(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895a96d1-aba9-4853-b62c-39326928b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(\n",
    "    public_key=\"key\",\n",
    "    secret_key=\"key\",\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9750e48-998d-4a39-99a2-d103c94b16c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 219 tensors from /home/arseniy/Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹/Projects/Python/LLM_project/models/pip-sql-1.3b.Q8_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = pip-sql-1.3b\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 24\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 5504\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 16\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 100000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 32256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                    llama.rope.scaling.type str              = linear\n",
      "llama_model_loader: - kv  14:                  llama.rope.scaling.factor f32              = 4.000000\n",
      "llama_model_loader: - kv  15:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  16:                         tokenizer.ggml.pre str              = deepseek-coder\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.tokens arr[str,32256]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  18:                  tokenizer.ggml.token_type arr[i32,32256]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  19:                      tokenizer.ggml.merges arr[str,31757]   = [\"Ä  Ä \", \"Ä  t\", \"Ä  a\", \"i n\", \"h e...\n",
      "llama_model_loader: - kv  20:                tokenizer.ggml.bos_token_id u32              = 32013\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.eos_token_id u32              = 32021\n",
      "llama_model_loader: - kv  22:            tokenizer.ggml.padding_token_id u32              = 32021\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {<schma>{}</schema><question>{}</ques...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   49 tensors\n",
      "llama_model_loader: - type q8_0:  170 tensors\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.1787 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 32256\n",
      "llm_load_print_meta: n_merges         = 31757\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 2048\n",
      "llm_load_print_meta: n_layer          = 24\n",
      "llm_load_print_meta: n_head           = 16\n",
      "llm_load_print_meta: n_head_kv        = 16\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 2048\n",
      "llm_load_print_meta: n_embd_v_gqa     = 2048\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 5504\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 100000.0\n",
      "llm_load_print_meta: freq_scale_train = 0.25\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q8_0\n",
      "llm_load_print_meta: model params     = 1.35 B\n",
      "llm_load_print_meta: model size       = 1.33 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name     = pip-sql-1.3b\n",
      "llm_load_print_meta: BOS token        = 32013 '<ï½œbeginâ–ofâ–sentenceï½œ>'\n",
      "llm_load_print_meta: EOS token        = 32021 '<|EOT|>'\n",
      "llm_load_print_meta: PAD token        = 32021 '<|EOT|>'\n",
      "llm_load_print_meta: LF token         = 126 'Ã„'\n",
      "llm_load_print_meta: max token length = 128\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    no\n",
      "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
      "ggml_cuda_init: found 1 CUDA devices:\n",
      "  Device 0: NVIDIA GeForce GTX 1650, compute capability 7.5, VMM: yes\n",
      "llm_load_tensors: ggml ctx size =    0.20 MiB\n",
      "llm_load_tensors: offloading 22 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 22/25 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  1364.63 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  1128.19 MiB\n",
      "warning: failed to mlock 71360512-byte buffer (after previously locking 0 bytes): Cannot allocate memory\n",
      "Try increasing RLIMIT_MEMLOCK ('ulimit -l' as root).\n",
      ".............................................................................................\n",
      "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
      "llama_new_context_with_model: n_ctx      = 10016\n",
      "llama_new_context_with_model: n_batch    = 32\n",
      "llama_new_context_with_model: n_ubatch   = 32\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =   156.50 MiB\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =  1721.50 MiB\n",
      "llama_new_context_with_model: KV self size  = 1878.00 MiB, K (f16):  939.00 MiB, V (f16):  939.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   102.56 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     1.72 MiB\n",
      "llama_new_context_with_model: graph nodes  = 774\n",
      "llama_new_context_with_model: graph splits = 26\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
      "Model metadata: {'tokenizer.chat_template': '{<schma>{}</schema><question>{}</question><sql>}', 'tokenizer.ggml.padding_token_id': '32021', 'tokenizer.ggml.eos_token_id': '32021', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.scaling.factor': '4.000000', 'general.architecture': 'llama', 'llama.rope.freq_base': '100000.000000', 'tokenizer.ggml.pre': 'deepseek-coder', 'llama.context_length': '16384', 'general.name': 'pip-sql-1.3b', 'llama.rope.scaling.type': 'linear', 'llama.embedding_length': '2048', 'llama.feed_forward_length': '5504', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'tokenizer.ggml.bos_token_id': '32013', 'llama.attention.head_count': '16', 'llama.block_count': '24', 'llama.attention.head_count_kv': '16', 'general.file_type': '7', 'llama.vocab_size': '32256', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {<schma>{}</schema><question>{}</question><sql>}\n",
      "Using chat eos_token: <|EOT|>\n",
      "Using chat bos_token: <ï½œbeginâ–ofâ–sentenceï½œ>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatLlamaCpp \n",
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "import multiprocessing\n",
    "\n",
    "# Path to the model weights\n",
    "models_directory = '/home/arseniy/Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹/Projects/Python/LLM_project/models/'\n",
    "\n",
    "local_model = models_directory + 'pip-sql-1.3b.Q8_0.gguf' \n",
    "\n",
    "\n",
    "llm = ChatLlamaCpp(\n",
    "    model_path = local_model,\n",
    "    temperature = 0.01,\n",
    "    n_ctx=10000,\n",
    "    repeat_penalty = 2,\n",
    "    n_threads=8,\n",
    "    n_gpu_layers=22,\n",
    "    use_mlock = True,\n",
    "    versbose = True,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "704695ff-cb32-4574-85b0-8ce8e0d2243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "#sql_chain = create_sql_query_chain(llm, db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1767ceaf-d1be-4512-b016-c7e6c276daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fewShot_promting = True\n",
    "check_query = True\n",
    "enable_vector_db = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2755aae9-cf52-473b-af47-336c0c872213",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples =[\n",
    "    {\n",
    "        \"input\": \"List all projects.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM mysProjects;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all projects managed by 'Jolene Duran'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM mysProjects WHERE manager = 'Jolene Duran';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all projects with project code 'MY0849'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM mysProjects WHERE project_code = 'MY0849';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees in the 'finance & accounting' hierarchy level.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM orgHierarchy WHERE hierarchy_level = 'finance & accounting';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all work histories for 'Ä°stanbul Bilgi Ãœniversitesi Tercih GÃ¼nler'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM workHistory WHERE company = 'Ä°stanbul Bilgi Ãœniversitesi Tercih GÃ¼nler';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all certifications with the name 'Ms Project'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM certification WHERE name = 'Ms Project';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all comments given by 'Knight Eaton'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM comments WHERE evaluator = 'Knight Eaton';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who attended 'Erciyes Ãœniversitesi'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM educations WHERE school = 'Erciyes Ãœniversitesi';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all employees.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM employees;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who are not absent.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM employees WHERE is_absent = 0;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all languages spoken by employee with id '1'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM languages WHERE employee_id = 1;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all leave records for employee with id '2'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM leaves WHERE employee_id = 2;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all score details for score id '1'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM score_details WHERE score_id = 1;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all scores evaluated by 'Eve Mccarty'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM scores WHERE evaluator = 'Eve Mccarty';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all software skills for employee with id '1'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT * FROM softwares WHERE employee_id = 1;\n",
    "        \"\"\"\n",
    "    },    \n",
    "    {\n",
    "        \"input\": \"List all employees along with their total number of certifications.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*, COUNT(c.id) as certification_count \n",
    "            FROM employees e\n",
    "            LEFT JOIN certification c ON e.id = c.employee_id\n",
    "            GROUP BY e.id;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who have received comments with a score higher than '4' in the last year.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.* \n",
    "            FROM employees e\n",
    "            JOIN comments cm ON e.id = cm.employee_id\n",
    "            WHERE cm.score > 4 AND cm.date_time >= DATE('now', '-1 year');\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all employees who have obtained a certification in 'Project Management' and are currently not absent.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.* \n",
    "            FROM employees e\n",
    "            JOIN certification c ON e.id = c.employee_id\n",
    "            WHERE c.name = 'Project Management' AND e.is_absent = 0;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find the total number of employees in each directorate.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT directorate, COUNT(*) as total_employees \n",
    "            FROM employees\n",
    "            GROUP BY directorate;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all employees who have completed their education in the 'Computer Science' department with a 'Bachelor' degree.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.* \n",
    "            FROM employees e\n",
    "            JOIN educations ed ON e.id = ed.employee_id\n",
    "            WHERE ed.department = 'Computer Science' AND ed.degree = 'Bachelor';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who have worked in more than one company.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*, COUNT(w.id) as companies_count\n",
    "            FROM employees e\n",
    "            JOIN workHistory w ON e.id = w.employee_id\n",
    "            GROUP BY e.id\n",
    "            HAVING companies_count > 1;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all employees along with their average comment score.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*, AVG(cm.score) as average_score\n",
    "            FROM employees e\n",
    "            LEFT JOIN comments cm ON e.id = cm.employee_id\n",
    "            GROUP BY e.id;\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who have both certifications in 'Data Science' and 'Machine Learning'.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*\n",
    "            FROM employees e\n",
    "            JOIN certification c1 ON e.id = c1.employee_id AND c1.name = 'Data Science'\n",
    "            JOIN certification c2 ON e.id = c2.employee_id AND c2.name = 'Machine Learning';\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"List all employees who are older than 40 years and have a certification that expired last year.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*\n",
    "            FROM employees e\n",
    "            JOIN certification c ON e.id = c.employee_id\n",
    "            WHERE e.age > 40 AND c.end_date BETWEEN DATE('now', '-1 year') AND DATE('now');\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Find all employees who have completed education in 'Engineering' and have received at least three certifications.\",\n",
    "        \"query\": \"\"\"\n",
    "            SELECT e.*\n",
    "            FROM employees e\n",
    "            JOIN educations ed ON e.id = ed.employee_id AND ed.department = 'Engineering'\n",
    "            JOIN certification c ON e.id = c.employee_id\n",
    "            GROUP BY e.id\n",
    "            HAVING COUNT(c.id) >= 3;\n",
    "        \"\"\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241ac073-4a5f-4530-825c-f46021b4e822",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for FewShotPromptTemplate\nexample_prompt\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#example_prompt =  PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fewShot_promting):\n\u001b[0;32m----> 8\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[43mFewShotPromptTemplate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#example_prompt=example_prompt,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run. Unless otherwise specified, do not return more than \u001b[39;49m\u001b[38;5;132;43;01m{top_k}\u001b[39;49;00m\u001b[38;5;124;43m rows. Here is the relevant database schema info: \u001b[39;49m\u001b[38;5;132;43;01m{table_info}\u001b[39;49;00m\u001b[38;5;124;43m. If filtering on a feature value make sure to check its spelling. Always check the spelling of column names! Write only SQL query! Dont write anything else! Try to keep SQL query short. Write SQL query only about the question user asked.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                        \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser input: \u001b[39;49m\u001b[38;5;132;43;01m{input}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSQL query: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtable_info\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     query_chain \u001b[38;5;241m=\u001b[39m create_sql_query_chain(llm, db, prompt)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(enable_vector_db):\n",
      "File \u001b[0;32m~/.var/app/org.jupyter.JupyterLab/config/jupyterlab-desktop/jlab_server/envs/llamaCuda/lib/python3.12/site-packages/langchain_core/prompts/few_shot.py:142\u001b[0m, in \u001b[0;36mFewShotPromptTemplate.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    141\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39minput_variables\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.var/app/org.jupyter.JupyterLab/config/jupyterlab-desktop/jlab_server/envs/llamaCuda/lib/python3.12/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for FewShotPromptTemplate\nexample_prompt\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "dialect = 'SQLite'\n",
    "\n",
    "#example_prompt =  PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\")\n",
    "\n",
    "if (fewShot_promting):\n",
    "    prompt = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        #example_prompt=example_prompt,\n",
    "        prefix = \"You are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run. Unless otherwise specified, do not return more than {top_k} rows. Here is the relevant database schema info: {table_info}. If filtering on a feature value make sure to check its spelling. Always check the spelling of column names! Write only SQL query! Dont write anything else! Try to keep SQL query short. Write SQL query only about the question user asked.\",\n",
    "        \n",
    "                        \n",
    "        suffix=\"User input: {input}\\nSQL query: \",\n",
    "        input_variables=[\"input\", \"top_k\", \"table_info\"],\n",
    "    )\n",
    "    query_chain = create_sql_query_chain(llm, db, prompt)\n",
    "    \n",
    "    if(enable_vector_db):\n",
    "        retriever_chain = (\n",
    "        itemgetter(\"question\")\n",
    "        | retriever\n",
    "        | (lambda docs: \"\\n\".join(doc.page_content for doc in docs))\n",
    "        )\n",
    "        chain = RunnablePassthrough.assign(emails=retriever_chain) | query_chain\n",
    "else:\n",
    "    query_chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97af70e-7394-4bcb-8cfa-ebfad8fc5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('description.txt', 'r') as file:\n",
    "    description = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d682e-ec2b-4efd-8737-07d2fd0d6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "\n",
    "dialect = 'SQLite'\n",
    "\n",
    "example_prompt =  PromptTemplate.from_template(\"User input: {input}\\nSQL query: {query}\")\n",
    "\n",
    "if (fewShot_promting):\n",
    "    prompt = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix = \"You are a SQLite expert. Given an input question, create a syntactically correct SQLite query to run. Unless otherwise specified, do not return more than {top_k} rows. Here is the relevant database schema info: {table_info}. If filtering on a feature value make sure to check its spelling. Check the provided description for the database: {table_info} .Always check the spelling of column names! Write only SQL query! Dont write anything else! Try to keep SQL query short. Write SQL query only about the question user asked.\",           \n",
    "        suffix=\"User input: {input}\\nSQL query: \",\n",
    "        input_variables=[\"input\", \"top_k\", \"table_info\", \"description\"],\n",
    "    )\n",
    "    query_chain = create_sql_query_chain(llm, db, prompt)\n",
    "    \n",
    "    if(enable_vector_db):\n",
    "        retriever_chain = (\n",
    "        itemgetter(\"question\")\n",
    "        | retriever\n",
    "        | (lambda docs: \"\\n\".join(doc.page_content for doc in docs))\n",
    "        )\n",
    "        chain = RunnablePassthrough.assign(emails=retriever_chain) | query_chain\n",
    "else:\n",
    "    query_chain = create_sql_query_chain(llm, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3ec83-55d0-40f0-8679-5e47d8133324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_query_result_to_text(prompt, query_result):\n",
    "    # Convert query result to text\n",
    "    result_text = f\"The query result is: {query_result}\"\n",
    "    \n",
    "    # Create input for the chain that will interpret the query result\n",
    "    interpretation_prompt = f\"Based on the user question: '{prompt}' and database query result: '{query_result}', interpret the results. Write it very simple words, without any technical details. Write very short. Dont exceed one sentence. Make it understandable for human without knowing tecnical details.\"\n",
    "    \n",
    "    # Use another chain to interpret the query result\n",
    "    interpretation = llm2.invoke(interpretation_prompt)\n",
    "    \n",
    "    return interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37928f1-446f-4689-b0eb-80b3d9213e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlvalidator\n",
    "import sqlcorrect as sc\n",
    "\n",
    "def main():\n",
    "    print(\"ðŸ”´ Simple database chatbot app. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        # Get user input\n",
    "        question = input(\"ðŸŸ¢ Enter your question: \")\n",
    "        #memory.chat_memory.add_user_message(question)\n",
    "        if question.lower() == 'exit':\n",
    "            print(\"Exiting the app.\")\n",
    "            break\n",
    "        \n",
    "        # Invoke the chain with the user's question\n",
    "        # if check_query = True, then query checking operation will be performed.\n",
    "        if (check_query): \n",
    "            response = full_chain.invoke({\"question\": question}, input_variables={\"vocabulary\": email},config={\"callbacks\": [langfuse_handler]} ) \n",
    "        elif (enable_vector_db): \n",
    "            response = chain.invoke({\"question\": question + \" Check the spelling of attributes in the question from the lsit of values which you have! Especially check the spelling of names, emails, titles!!! Write only the SQL query, nothing more! \"}, config={\"callbacks\": [langfuse_handler]}) \n",
    "        else:\n",
    "            response = query_chain.invoke({\"question\": question }, config={\"callbacks\": [langfuse_handler]}) \n",
    "\n",
    "        #corrected_query = sc.correct_sql_query(response)\n",
    "        print(\"Response:\", response)\n",
    "        \n",
    "        sql_query = sqlvalidator.format_sql(response)\n",
    "        print(\"Formated SQL:\" + sql_query)\n",
    "        \n",
    "        #memory.chat_memory.add_ai_message(sql_query) \n",
    "        try:\n",
    "            db_answer = db.run(sql_query)\n",
    "            print(db_answer)\n",
    "            #rint(convert_query_result_to_text(question, db_answer))\n",
    "        except:\n",
    "            print(\"ðŸ”´ LLM agent gave a wrong SQL query. Paraphrase the question...\")\n",
    "            #print(convert_query_result_to_text(question, db_answer))\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
